{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "[CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。然后要构建模型：卷积层、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片进行神经网络的预测。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "数据集下载地址[CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "import problem_unittests as tests\n",
    "cifar10_dataset_folder_path = './cifar-10-python/cifar-10-batches-py'\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 2:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}\n",
      "First 20 Labels: [1, 6, 6, 8, 8, 3, 4, 6, 0, 6, 0, 3, 6, 6, 5, 4, 8, 3, 2, 6]\n",
      "\n",
      "Example of Image 20:\n",
      "Image - Min Value: 24 Max Value: 206\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 231,
       "width": 231
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# 探索数据集\n",
    "batch_id = 2\n",
    "sample_id = 20\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    归一化处理图片数据，将其缩放到（0,1）\n",
    "    : x: 图片数据.  图片的shape= (32, 32, 3)\n",
    "    : return: 归一化的numpy数组\n",
    "    \"\"\"\n",
    "    # 需要编程: 部署函数\n",
    "    result=0+(x-x.min())*1.0/(x.max()-x.min())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "需要实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    : x: 样品标签\n",
    "    : return: 独热编码标签 是一个numpy 数组\n",
    "    \"\"\"\n",
    "    # 需要编程: 部署函数\n",
    "    encode=[]\n",
    "    for value in x:\n",
    "        list=np.zeros([10])\n",
    "        list[value]=1\n",
    "        encode.append(list)\n",
    "    return np.array(encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理训练数据集，验证数据集，测试数据集\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是第一个检查点。重新启动记事本后，可以从这里开始。因为预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import helper\n",
    "# 读取已经保存的验证数据集 \n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "我们将为每层都构建为一个函数。\n",
    "\n",
    ">**注意**：你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 层级类似，因此很容易学会。\n",
    "\n",
    ">对初学者，还是建议使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。需要完成以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    返回一个tensor（placeholder）:批量输入的图片\n",
    "    : image_shape:the shape of image.\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    #7*7*64\n",
    "    # 需要编程: 完成这个函数\n",
    "    layer_0=tf.placeholder(tf.float32,[None,image_shape[0],\n",
    "                                       image_shape[1],\n",
    "                                       image_shape[2]],\n",
    "                           name='x')\n",
    "    return layer_0\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    返回一个tensor（placeholder）:批量输入的标签\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # 需要编程: 完成这个函数\n",
    "    label=tf.placeholder(tf.float32,[None,n_classes],\n",
    "                         name='y')\n",
    "    return label\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    返回一个tensor（placeholder）:保留的概率(1-dropout)\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # 需要编程: 完成这个函数\n",
    "    prob=tf.placeholder(tf.float32,name='keep_prob')\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。在整个cell中，我们要实现函数 `conv2d_maxpool` 应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**这个cell的**，**不能使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    先时实现卷积，然后再实现最大池化\n",
    "    :x_tensor: TensorFlow Tensor\n",
    "    :conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :conv_strides: Stride 2-D Tuple for convolution\n",
    "    :pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # 需要编程: 完成这个函数\n",
    "    #调参点1：初始化方法\n",
    "    #调参点2： 均方差（tf.random_normal,truncated_normal都是默认为1）\n",
    "    #调参点3：padding\n",
    "    #调参点4：conv_ksize(卷积核大小)\n",
    "    #batchsize,height,width,channel\n",
    "    #n*32*32*3   5*5*3*\n",
    "    filter_weights=tf.Variable(tf.truncated_normal([conv_ksize[0],\n",
    "                                                    conv_ksize[1],\n",
    "                                                    x_tensor.get_shape().as_list()[3],\n",
    "                                                    conv_num_outputs],stddev=0.05))\n",
    "    bias=tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    conv_layer=tf.nn.conv2d(x_tensor,filter_weights,\n",
    "                            strides=[1,conv_strides[0],conv_strides[1],1],padding=\"SAME\")\n",
    "    conv_layer=tf.nn.bias_add(conv_layer,bias)\n",
    "    #conv_layer=tf.nn.relu(conv_layer)\n",
    "    conv_layer=tf.nn.max_pool(conv_layer,ksize=[1,pool_ksize[0],pool_ksize[1],1],\n",
    "                              strides=[1,pool_strides[0],pool_strides[1],1],\n",
    "                              padding='SAME')\n",
    "    conv_layer=tf.nn.relu(conv_layer)\n",
    "    return conv_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # 编程实现：\n",
    "    #7*7*64\n",
    "    #batchsize*height*width*channel\n",
    "    #下一个全连接层的维度 应该就 [height*width*channel,out_number]\n",
    "    image_size=(x_tensor.get_shape().as_list()[1])*(x_tensor.get_shape().\n",
    "                                                    as_list()[2])*(x_tensor.get_shape().\n",
    "                                                                   as_list()[3])\n",
    "    ten1=tf.reshape(x_tensor,[-1,image_size])\n",
    "    return ten1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    #调参点，方差\n",
    "    full_weights=tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1],\n",
    "                                                  num_outputs],stddev=0.1))\n",
    "    full_bias=tf.Variable(tf.zeros([num_outputs]))\n",
    "    result=tf.matmul(x_tensor,full_weights)+full_bias\n",
    "    result=tf.nn.relu(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。\n",
    "\n",
    "**注意**：该层级不用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # 需要编程实现：\n",
    "    out_weights=tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1],\n",
    "                                                 num_outputs],stddev=0.1))\n",
    "    out_bias=tf.Variable(tf.zeros([num_outputs]))\n",
    "    result=tf.matmul(x_tensor,out_weights)+out_bias\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用我们在上面创建的层创建模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)\n",
    "<img src='conv_model.png' width=1000px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    : x: Placeholder tensor -- image data.\n",
    "    : keep_prob: Placeholder tensor -- dropout keep probability.\n",
    "    : return: Tensor  represents logits\n",
    "    \"\"\"\n",
    "    # 需要编程: 可以尝试1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    可以试试不同的参数（主要指卷积）, kernel size and stride\n",
    "    # 函数定义如下：\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    #conv_num_outputs=32\n",
    "    #conv_ksize=(5,5)\n",
    "    #conv_strides=(1,1)\n",
    "    #pool_ksize=(2,2)\n",
    "    #pool_strides=(2,2)\n",
    "    #调参点1：网络的层数\n",
    "    #调参点2：卷积核个数\n",
    "    c_layer=conv2d_maxpool(x,64,(3,3), (1,1), \n",
    "                           (2,2), (2,2))\n",
    "    #c_layer=tf.nn.dropout(c_layer,keep_prob)\n",
    "\n",
    "    c_layer=conv2d_maxpool(c_layer,128,(3,3), \n",
    "                           (1,1), (2,2), (2,2))\n",
    "    #c_layer=tf.nn.dropout(c_layer,keep_prob)\n",
    "\n",
    "    c_layer=conv2d_maxpool(c_layer,256,(3,3), \n",
    "                           (1,1), (2,2), (2,2))\n",
    "    #c_layer=tf.nn.dropout(c_layer,keep_prob)\n",
    "\n",
    "    # 需要编程: 应用扁平层 \n",
    "    # 函数定义如下:\n",
    "    #   flatten(x_tensor)\n",
    "    c_layer=flatten(c_layer)\n",
    "\n",
    "    # 需要编程: 尝试应用1, 2, 或者 3 全连接层\n",
    "    # 函数定义如下:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    num_outputs=1024\n",
    "    c_layer=fully_conn(c_layer,num_outputs)\n",
    "    c_layer=tf.nn.dropout(c_layer,keep_prob)\n",
    "    \n",
    "    # 需要编程:应用一个输出层\n",
    "    # 函数定义如下:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    c_layer=output(c_layer,10)\n",
    "    \n",
    "    # 需要编程:return output\n",
    "    return c_layer\n",
    "\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# 移除之前所有的tensor：权重，偏置项，输入\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 输入\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# 模型\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# 命名 logits Tensor, 以便后面调用\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "完成函数 `train_neural_network` 进行单次优化（single optimization）。该优化使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示dropout的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。函数只是用来优化神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # 需要你编程：\n",
    "    session.run(optimizer,feed_dict={x:feature_batch,\n",
    "                                     y:label_batch,\n",
    "                                     keep_prob:keep_probability})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "完成函数 `print_stats` 输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # 需要编程：\n",
    "    loss=session.run(cost,feed_dict={x:feature_batch,\n",
    "                                     y:label_batch,\n",
    "                                     keep_prob:1.0})\n",
    "    valid_cc=session.run(accuracy,feed_dict={x:valid_features[:],\n",
    "                                             y:valid_labels[:],\n",
    "                                             keep_prob:1.0})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.\n",
    "          format(loss,valid_cc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用dropout时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要设置: 调整设置超参数\n",
    "#重点调参的位置\n",
    "epochs = 60\n",
    "batch_size = 512#2048=>\n",
    "keep_probability = 0.6#0.6.0.7,0.4,0.8,0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在单个批量数据上训练...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.0394 Validation Accuracy: 0.302000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.7630 Validation Accuracy: 0.391800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.6052 Validation Accuracy: 0.434400\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.4417 Validation Accuracy: 0.474000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.3015 Validation Accuracy: 0.499800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.2095 Validation Accuracy: 0.511000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.0681 Validation Accuracy: 0.552600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.9812 Validation Accuracy: 0.548800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.8927 Validation Accuracy: 0.577800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.7493 Validation Accuracy: 0.583400\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.6968 Validation Accuracy: 0.582600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.5747 Validation Accuracy: 0.602000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.4906 Validation Accuracy: 0.618400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.4075 Validation Accuracy: 0.624200\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.3959 Validation Accuracy: 0.609000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.3636 Validation Accuracy: 0.605200\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.3034 Validation Accuracy: 0.610400\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.2906 Validation Accuracy: 0.585600\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.2338 Validation Accuracy: 0.619000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.1904 Validation Accuracy: 0.627400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.1578 Validation Accuracy: 0.610000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.1336 Validation Accuracy: 0.616600\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.1090 Validation Accuracy: 0.622800\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.1185 Validation Accuracy: 0.597800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.0986 Validation Accuracy: 0.606400\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.0665 Validation Accuracy: 0.614400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.0442 Validation Accuracy: 0.640600\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.0655 Validation Accuracy: 0.613200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.0465 Validation Accuracy: 0.617400\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.0296 Validation Accuracy: 0.634600\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.0288 Validation Accuracy: 0.619400\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.0421 Validation Accuracy: 0.604600\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.0223 Validation Accuracy: 0.630600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.0204 Validation Accuracy: 0.623600\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.0102 Validation Accuracy: 0.633000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.0153 Validation Accuracy: 0.627800\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.0076 Validation Accuracy: 0.633200\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.0219 Validation Accuracy: 0.600600\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.0081 Validation Accuracy: 0.635400\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.0074 Validation Accuracy: 0.637200\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.0068 Validation Accuracy: 0.627600\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.0075 Validation Accuracy: 0.623600\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.0027 Validation Accuracy: 0.642200\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.0031 Validation Accuracy: 0.640400\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.0017 Validation Accuracy: 0.645800\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.0012 Validation Accuracy: 0.646600\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.0017 Validation Accuracy: 0.642800\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.0010 Validation Accuracy: 0.648200\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.0010 Validation Accuracy: 0.643600\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.0007 Validation Accuracy: 0.644800\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.0009 Validation Accuracy: 0.646200\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.0010 Validation Accuracy: 0.645200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-48873681629e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mbatch_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_preprocess_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {:>2}, CIFAR-10 Batch {}:  '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-9cede4cce6be>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[1;34m(session, optimizer, keep_probability, feature_batch, label_batch)\u001b[0m\n\u001b[0;32m     11\u001b[0m     session.run(optimizer,feed_dict={x:feature_batch,\n\u001b[0;32m     12\u001b[0m                                      \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                                      keep_prob:keep_probability})\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\beifeng2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\beifeng2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\beifeng2\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('在单个批量数据上训练...')\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    # 初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 训练过程\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('训练...')\n",
    "with tf.Session() as sess:\n",
    " \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 训练过程\n",
    "    for epoch in range(epochs):\n",
    "        # 遍历所有batch\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # 保存模型\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "请勿改动本单元内代码\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # 读取模型\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # 从已经读入的模型中 获取tensors \n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # 获取每个batch的准确率，再求平均值，这样可以节约内存\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # 随机打印一个例子\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "https://cs231n.github.io/convolutional-networks/#case\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
